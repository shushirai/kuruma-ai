import cv2
import torch
from torchvision import models, transforms
from PIL import Image
import os

# âœ… è»Šç¨®åãƒªã‚¹ãƒˆ
car_prices = {
    "Toyota Prius": {"æ–°è»Šä¾¡æ ¼": "275ä¸‡å††ã€œ460ä¸‡å††", "ä¸­å¤ä¾¡æ ¼": "3.7ä¸‡å††ã€œ569ä¸‡å††"},
    "Honda Fit": {"æ–°è»Šä¾¡æ ¼": "172ä¸‡å††ã€œ250.7ä¸‡å††", "ä¸­å¤ä¾¡æ ¼": "4.8ä¸‡å††ã€œ290ä¸‡å††"},
    "Nissan Note": {"æ–°è»Šä¾¡æ ¼": "229.9ä¸‡å††ã€œ306.4ä¸‡å††", "ä¸­å¤ä¾¡æ ¼": "5ä¸‡å††ã€œ295ä¸‡å††"},
}
class_names = list(car_prices.keys())

# âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
def load_model(model_path="./models/best_model.pth", num_classes=len(class_names)):
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()
    return model

model = load_model()

# âœ… å‰å‡¦ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# âœ… å‹•ç”»æ¨è«–ï¼‹ä¿å­˜
def predict_video(input_video_path, output_video_path="output_predicted.mp4", threshold=0.6):
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print("âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        input_tensor = transform(img_pil).unsqueeze(0)
        with torch.no_grad():
            outputs = model(input_tensor)
            probs = torch.nn.functional.softmax(outputs, dim=1)[0]
            top_prob, top_idx = torch.topk(probs, k=1)

            confidence = top_prob.item()
            label = class_names[top_idx.item()]

        # ğŸ”– åˆ¤å®šãƒ©ãƒ™ãƒ«
        if confidence < threshold:
            text = f"åˆ¤å®šä¸èƒ½ ({confidence:.2f})"
        else:
            text = f"{label} ({confidence:.2f})"

        # âœï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ›¸ãè¾¼ã¿
        cv2.putText(frame, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX,
                    1.0, (0, 255, 0), 2, cv2.LINE_AA)

        out.write(frame)

        frame_count += 1
        if frame_count % 30 == 0:
            print(f"âœ… {frame_count} ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ä¸­...")

    cap.release()
    out.release()
    print(f"ğŸ¥ ä¿å­˜å®Œäº†: {output_video_path}")

# âœ… ä½¿ç”¨ä¾‹ï¼ˆã‚ã¨ã§ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰å‘¼ã³å‡ºã—ã¦ã‚‚OKï¼‰
predict_video("test1.mp4", output_video_path="your_output_video.mp4")
